<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ros_jetson_tensorrt: jetson_tensorrt::TensorRTEngine Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ros_jetson_tensorrt
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>jetson_tensorrt</b></li><li class="navelem"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html">TensorRTEngine</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classjetson__tensorrt_1_1_tensor_r_t_engine-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">jetson_tensorrt::TensorRTEngine Class Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p>Abstract base class which loads and manages a TensorRT model which hides device/host memory management.  
 <a href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_tensor_r_t_engine_8h_source.html">TensorRTEngine.h</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for jetson_tensorrt::TensorRTEngine:</div>
<div class="dyncontent">
<div class="center"><img src="classjetson__tensorrt_1_1_tensor_r_t_engine__inherit__graph.png" border="0" usemap="#jetson__tensorrt_1_1_tensor_r_t_engine_inherit__map" alt="Inheritance graph"/></div>
<map name="jetson__tensorrt_1_1_tensor_r_t_engine_inherit__map" id="jetson__tensorrt_1_1_tensor_r_t_engine_inherit__map">
<area shape="rect" id="node2" href="classjetson__tensorrt_1_1_caffe_r_t_engine.html" title="Loads and manages a Caffe network in TensorRT. " alt="" coords="128,85,336,111"/>
<area shape="rect" id="node5" href="classjetson__tensorrt_1_1_tensorflow_r_t_engine.html" title="Loads and manages a Tensorflow network in TensorRT. " alt="" coords="360,79,541,117"/>
<area shape="rect" id="node3" href="classjetson__tensorrt_1_1_d_i_g_i_t_s_classifier.html" title="Loads and manages a DIGITS ImageNet graph with TensorRT. " alt="" coords="5,165,222,191"/>
<area shape="rect" id="node4" href="classjetson__tensorrt_1_1_d_i_g_i_t_s_detector.html" title="Loads and manages a DIGITS DetectNet graph with TensorRT. " alt="" coords="245,165,457,191"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for jetson_tensorrt::TensorRTEngine:</div>
<div class="dyncontent">
<div class="center"><img src="classjetson__tensorrt_1_1_tensor_r_t_engine__coll__graph.png" border="0" usemap="#jetson__tensorrt_1_1_tensor_r_t_engine_coll__map" alt="Collaboration graph"/></div>
<map name="jetson__tensorrt_1_1_tensor_r_t_engine_coll__map" id="jetson__tensorrt_1_1_tensor_r_t_engine_coll__map">
<area shape="rect" id="node2" href="classjetson__tensorrt_1_1_logger.html" title="Logger for GIE info/warning/errors. " alt="" coords="34,80,193,105"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:add96fa4cc69af7f0c76db272931a8101"><td class="memItemLeft" align="right" valign="top"><a id="add96fa4cc69af7f0c76db272931a8101"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#add96fa4cc69af7f0c76db272931a8101">TensorRTEngine</a> ()</td></tr>
<tr class="memdesc:add96fa4cc69af7f0c76db272931a8101"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates and manages a new instance of <a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html" title="Abstract base class which loads and manages a TensorRT model which hides device/host memory managemen...">TensorRTEngine</a>. <br /></td></tr>
<tr class="separator:add96fa4cc69af7f0c76db272931a8101"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5827e6a45961997612abd071eb283489"><td class="memItemLeft" align="right" valign="top"><a id="a5827e6a45961997612abd071eb283489"></a>
virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#a5827e6a45961997612abd071eb283489">~TensorRTEngine</a> ()</td></tr>
<tr class="memdesc:a5827e6a45961997612abd071eb283489"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html" title="Abstract base class which loads and manages a TensorRT model which hides device/host memory managemen...">TensorRTEngine</a> destructor. <br /></td></tr>
<tr class="separator:a5827e6a45961997612abd071eb283489"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46cc29b4f63f68136406a7360aabb45b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#a46cc29b4f63f68136406a7360aabb45b">predict</a> (<a class="el" href="structjetson__tensorrt_1_1_located_execution_memory.html">LocatedExecutionMemory</a> &amp;inputs, <a class="el" href="structjetson__tensorrt_1_1_located_execution_memory.html">LocatedExecutionMemory</a> &amp;outputs)</td></tr>
<tr class="memdesc:a46cc29b4f63f68136406a7360aabb45b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Does a forward pass of the neural network loaded in TensorRT  Should be called after loading the graph and calling allocGPUBuffer()  <a href="#a46cc29b4f63f68136406a7360aabb45b">More...</a><br /></td></tr>
<tr class="separator:a46cc29b4f63f68136406a7360aabb45b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3cb4769d3d947aba0b9baeffc68f547e"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#a3cb4769d3d947aba0b9baeffc68f547e">loadCache</a> (std::string cachePath, size_t maxBatchSize=1)</td></tr>
<tr class="memdesc:a3cb4769d3d947aba0b9baeffc68f547e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Quick load the TensorRT optimized network  Should be called after addInput and addOutput without calling loadModel.  <a href="#a3cb4769d3d947aba0b9baeffc68f547e">More...</a><br /></td></tr>
<tr class="separator:a3cb4769d3d947aba0b9baeffc68f547e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a07eab63439fd6c12542d1f37540175a9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#a07eab63439fd6c12542d1f37540175a9">saveCache</a> (std::string cachePath)</td></tr>
<tr class="memdesc:a07eab63439fd6c12542d1f37540175a9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Save the TensorRT optimized network for quick loading in the future  Should be called after loadModel()  <a href="#a07eab63439fd6c12542d1f37540175a9">More...</a><br /></td></tr>
<tr class="separator:a07eab63439fd6c12542d1f37540175a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac170c23a337a439cb674a40b005483ff"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#ac170c23a337a439cb674a40b005483ff">engineSummary</a> ()</td></tr>
<tr class="memdesc:ac170c23a337a439cb674a40b005483ff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns a summary of the loaded network, inputs, and outputs.  <a href="#ac170c23a337a439cb674a40b005483ff">More...</a><br /></td></tr>
<tr class="separator:ac170c23a337a439cb674a40b005483ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7abf6bf75df01eab197bfac5e6ce570c"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#a7abf6bf75df01eab197bfac5e6ce570c">addInput</a> (std::string layerName, nvinfer1::Dims dims, size_t eleSize)=0</td></tr>
<tr class="memdesc:a7abf6bf75df01eab197bfac5e6ce570c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Abstract method which registers an input to the network.  <a href="#a7abf6bf75df01eab197bfac5e6ce570c">More...</a><br /></td></tr>
<tr class="separator:a7abf6bf75df01eab197bfac5e6ce570c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2759405de044e028586f068f5e631a61"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#a2759405de044e028586f068f5e631a61">addOutput</a> (std::string layerName, nvinfer1::Dims dims, size_t eleSize)=0</td></tr>
<tr class="memdesc:a2759405de044e028586f068f5e631a61"><td class="mdescLeft">&#160;</td><td class="mdescRight">Abstract method which registers an output to the network.  <a href="#a2759405de044e028586f068f5e631a61">More...</a><br /></td></tr>
<tr class="separator:a2759405de044e028586f068f5e631a61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2844f621525838cab8fc403e96c73af4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structjetson__tensorrt_1_1_located_execution_memory.html">LocatedExecutionMemory</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#a2844f621525838cab8fc403e96c73af4">allocInputs</a> (MemoryLocation location, bool skipMalloc=false)</td></tr>
<tr class="memdesc:a2844f621525838cab8fc403e96c73af4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Allocates a located execution memory structure for inputs.  <a href="#a2844f621525838cab8fc403e96c73af4">More...</a><br /></td></tr>
<tr class="separator:a2844f621525838cab8fc403e96c73af4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4c0b9b09d6273ad211d36196f47520bc"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structjetson__tensorrt_1_1_located_execution_memory.html">LocatedExecutionMemory</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classjetson__tensorrt_1_1_tensor_r_t_engine.html#a4c0b9b09d6273ad211d36196f47520bc">allocOutputs</a> (MemoryLocation location, bool skipMalloc=false)</td></tr>
<tr class="memdesc:a4c0b9b09d6273ad211d36196f47520bc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Allocates a located execution memory structure for outputs.  <a href="#a4c0b9b09d6273ad211d36196f47520bc">More...</a><br /></td></tr>
<tr class="separator:a4c0b9b09d6273ad211d36196f47520bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a2e7607ca0c07c4eafc68af1a8e5aae14"><td class="memItemLeft" align="right" valign="top"><a id="a2e7607ca0c07c4eafc68af1a8e5aae14"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>maxBatchSize</b></td></tr>
<tr class="separator:a2e7607ca0c07c4eafc68af1a8e5aae14"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae21681fa49f30a92585a70b0a78d48b3"><td class="memItemLeft" align="right" valign="top"><a id="ae21681fa49f30a92585a70b0a78d48b3"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>numBindings</b></td></tr>
<tr class="separator:ae21681fa49f30a92585a70b0a78d48b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a361ed692f7ee58e11fc09fb8b611e456"><td class="memItemLeft" align="right" valign="top"><a id="a361ed692f7ee58e11fc09fb8b611e456"></a>
nvinfer1::DataType&#160;</td><td class="memItemRight" valign="bottom"><b>dataType</b></td></tr>
<tr class="separator:a361ed692f7ee58e11fc09fb8b611e456"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3430066aaef2ead6f826dfe0ffff5b41"><td class="memItemLeft" align="right" valign="top"><a id="a3430066aaef2ead6f826dfe0ffff5b41"></a>
std::vector&lt; <a class="el" href="classjetson__tensorrt_1_1_network_input.html">NetworkInput</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>networkInputs</b></td></tr>
<tr class="separator:a3430066aaef2ead6f826dfe0ffff5b41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a054d0ea3c8eb979518936e939bb61fd5"><td class="memItemLeft" align="right" valign="top"><a id="a054d0ea3c8eb979518936e939bb61fd5"></a>
std::vector&lt; <a class="el" href="classjetson__tensorrt_1_1_network_output.html">NetworkOutput</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>networkOutputs</b></td></tr>
<tr class="separator:a054d0ea3c8eb979518936e939bb61fd5"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a29f0c3bbbc3e1b87ba0e92aef0450284"><td class="memItemLeft" align="right" valign="top"><a id="a29f0c3bbbc3e1b87ba0e92aef0450284"></a>
nvinfer1::ICudaEngine *&#160;</td><td class="memItemRight" valign="bottom"><b>engine</b></td></tr>
<tr class="separator:a29f0c3bbbc3e1b87ba0e92aef0450284"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a235cf2c491b9bd8d094a42e86dd5844c"><td class="memItemLeft" align="right" valign="top"><a id="a235cf2c491b9bd8d094a42e86dd5844c"></a>
nvinfer1::IExecutionContext *&#160;</td><td class="memItemRight" valign="bottom"><b>context</b></td></tr>
<tr class="separator:a235cf2c491b9bd8d094a42e86dd5844c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a988907fdc98bb4ddb231a819c71e357b"><td class="memItemLeft" align="right" valign="top"><a id="a988907fdc98bb4ddb231a819c71e357b"></a>
<a class="el" href="classjetson__tensorrt_1_1_logger.html">Logger</a>&#160;</td><td class="memItemRight" valign="bottom"><b>logger</b></td></tr>
<tr class="separator:a988907fdc98bb4ddb231a819c71e357b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Abstract base class which loads and manages a TensorRT model which hides device/host memory management. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a7abf6bf75df01eab197bfac5e6ce570c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7abf6bf75df01eab197bfac5e6ce570c">&#9670;&nbsp;</a></span>addInput()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void jetson_tensorrt::TensorRTEngine::addInput </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>layerName</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">nvinfer1::Dims&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>eleSize</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Abstract method which registers an input to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">layer</td><td>The name of the input layer (i.e. "input_1") </td></tr>
    <tr><td class="paramname">dims</td><td>Dimensions of the input layer. Must be in CHW format. Ex: (3, 640, 480) </td></tr>
    <tr><td class="paramname">eleSize</td><td>Size of each element in bytes </td></tr>
  </table>
  </dd>
</dl>

<p>Implemented in <a class="el" href="classjetson__tensorrt_1_1_caffe_r_t_engine.html#a069c0b9bb940323ebe97b0351a2d773f">jetson_tensorrt::CaffeRTEngine</a>, and <a class="el" href="classjetson__tensorrt_1_1_tensorflow_r_t_engine.html#a5e45db4146cacd2218601d9273800d8a">jetson_tensorrt::TensorflowRTEngine</a>.</p>

</div>
</div>
<a id="a2759405de044e028586f068f5e631a61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2759405de044e028586f068f5e631a61">&#9670;&nbsp;</a></span>addOutput()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void jetson_tensorrt::TensorRTEngine::addOutput </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>layerName</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">nvinfer1::Dims&#160;</td>
          <td class="paramname"><em>dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>eleSize</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Abstract method which registers an output to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">layer</td><td>The name of the input layer (i.e. "input_1") </td></tr>
    <tr><td class="paramname">dims</td><td>Dimension of outputs </td></tr>
    <tr><td class="paramname">eleSize</td><td>Size of each element in bytes </td></tr>
  </table>
  </dd>
</dl>

<p>Implemented in <a class="el" href="classjetson__tensorrt_1_1_tensorflow_r_t_engine.html#aff7580475377d4e86d59f016dd72f83a">jetson_tensorrt::TensorflowRTEngine</a>, and <a class="el" href="classjetson__tensorrt_1_1_caffe_r_t_engine.html#a33d219f730749dbb4cb62ce29e1934de">jetson_tensorrt::CaffeRTEngine</a>.</p>

</div>
</div>
<a id="a2844f621525838cab8fc403e96c73af4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2844f621525838cab8fc403e96c73af4">&#9670;&nbsp;</a></span>allocInputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structjetson__tensorrt_1_1_located_execution_memory.html">LocatedExecutionMemory</a> jetson_tensorrt::TensorRTEngine::allocInputs </td>
          <td>(</td>
          <td class="paramtype">MemoryLocation&#160;</td>
          <td class="paramname"><em>location</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>skipMalloc</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Allocates a located execution memory structure for inputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">location</td><td>Whether the memory should be allocated on the HOST, DEVICE, or MAPPED </td></tr>
    <tr><td class="paramname">skipMalloc</td><td>Create the input structure but do not allocate memory </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The allocated or mapped inputs </dd></dl>

</div>
</div>
<a id="a4c0b9b09d6273ad211d36196f47520bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4c0b9b09d6273ad211d36196f47520bc">&#9670;&nbsp;</a></span>allocOutputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structjetson__tensorrt_1_1_located_execution_memory.html">LocatedExecutionMemory</a> jetson_tensorrt::TensorRTEngine::allocOutputs </td>
          <td>(</td>
          <td class="paramtype">MemoryLocation&#160;</td>
          <td class="paramname"><em>location</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>skipMalloc</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Allocates a located execution memory structure for outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">location</td><td>Whether the memory should be allocated on the HOST, DEVICE, or MAPPED </td></tr>
    <tr><td class="paramname">skipMalloc</td><td>Create the input structure but do not allocate memory </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The allocated or mapped outputs </dd></dl>

</div>
</div>
<a id="ac170c23a337a439cb674a40b005483ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac170c23a337a439cb674a40b005483ff">&#9670;&nbsp;</a></span>engineSummary()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::string jetson_tensorrt::TensorRTEngine::engineSummary </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns a summary of the loaded network, inputs, and outputs. </p>
<dl class="section return"><dt>Returns</dt><dd>String containing the summary </dd></dl>

</div>
</div>
<a id="a3cb4769d3d947aba0b9baeffc68f547e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3cb4769d3d947aba0b9baeffc68f547e">&#9670;&nbsp;</a></span>loadCache()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void jetson_tensorrt::TensorRTEngine::loadCache </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>cachePath</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>maxBatchSize</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Quick load the TensorRT optimized network  Should be called after addInput and addOutput without calling loadModel. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">cachePath</td><td>Path to the network cache file </td></tr>
    <tr><td class="paramname">maxBatchSize</td><td>The max batch size of the saved network. If the batch size needs to be changed, the network should be rebuilt with the new size and not simply changed here. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a46cc29b4f63f68136406a7360aabb45b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46cc29b4f63f68136406a7360aabb45b">&#9670;&nbsp;</a></span>predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void jetson_tensorrt::TensorRTEngine::predict </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structjetson__tensorrt_1_1_located_execution_memory.html">LocatedExecutionMemory</a> &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structjetson__tensorrt_1_1_located_execution_memory.html">LocatedExecutionMemory</a> &amp;&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Does a forward pass of the neural network loaded in TensorRT  Should be called after loading the graph and calling allocGPUBuffer() </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>Graph inputs indexed by [batchIndex][inputIndex] </td></tr>
    <tr><td class="paramname">outputs</td><td>Graph inputs indexed by [batchIndex][inputIndex] </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a07eab63439fd6c12542d1f37540175a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07eab63439fd6c12542d1f37540175a9">&#9670;&nbsp;</a></span>saveCache()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void jetson_tensorrt::TensorRTEngine::saveCache </td>
          <td>(</td>
          <td class="paramtype">std::string&#160;</td>
          <td class="paramname"><em>cachePath</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Save the TensorRT optimized network for quick loading in the future  Should be called after loadModel() </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">cachePath</td><td>Path to the network cache file </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>src/tensorrt/<a class="el" href="_tensor_r_t_engine_8h_source.html">TensorRTEngine.h</a></li>
<li>src/tensorrt/<a class="el" href="_tensor_r_t_engine_8cpp.html">TensorRTEngine.cpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
